{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prerun(W_init, n_trials):\n",
    "    w = W_init\n",
    "    for t in range(n_trials):\n",
    "        H = single_hebbian_component(N, w, theta_stim, type='baseline'); eta = np.random.randn(N, N); prop_function = propensity(w, a)\n",
    "        w += (hebb_scaling * H * prop_function + rand_scaling * eta * prop_function) * learning_rate\n",
    "        if t % n_steps_per_norm == 0: normalisation(w)\n",
    "    return w\n",
    "\n",
    "def evolve_W(W_old, t, type):\n",
    "    H = single_hebbian_component(N, W_old, theta_stim, type=type)\n",
    "    eta = np.random.randn(N, N)\n",
    "    prop_function = propensity(W_old, a)\n",
    "    hebb =  hebb_scaling * H * prop_function\n",
    "    rand =  rand_scaling * eta * prop_function\n",
    "    W_new = W_old + (hebb + rand) * learning_rate\n",
    "    if t % n_steps_per_norm == 0: \n",
    "        normalisation(W_new)\n",
    "        if t % (n_steps_per_norm * n_norm_per_day) == 0: PO = get_preferred_orientations(N, W_old, n_angles=n_test_angles); POs.append(PO)    \n",
    "    return W_new\n",
    "\n",
    "def get_POs_over_trials(W_init, n_steps, type):\n",
    "    global POs; POs = []\n",
    "    W = np.zeros((N, N, n_steps+1)); W[:, :, 0] = W_init\n",
    "    for t in tqdm(range(n_steps)):\n",
    "        W[:, :, t+1] = evolve_W(W[:, :, t], t, type)\n",
    "    return POs\n",
    "\n",
    "def get_POs_over_trials_7(W_baseline, n_steps):\n",
    "    global POs; POs = []; \n",
    "    W = np.zeros((N, N, n_steps+1)); W[:, :, 0] = W_baseline\n",
    "    for t in tqdm(range(n_steps)):\n",
    "        if t % (n_steps_per_norm * n_norm_per_day * 7) == 0 and t != 0:\n",
    "            t_if = t  \n",
    "            while t < t_if + (n_steps_per_norm * n_norm_per_day) * 7:\n",
    "                W[:, :, t+1] = evolve_W(W[:, :, t], t, 'test')\n",
    "                t += 1  \n",
    "        else:\n",
    "           W[:, :, t+1] = evolve_W(W[:, :, t], t, 'stripe_rearing')\n",
    "    return POs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics over days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(500)                                                        # Number of neurons\n",
    "a = 10                                                              # Parameters for propensity function\n",
    "theta_stim = 90                                                     # Angle to stimulate at \n",
    "n_test_angles = 100                                                 # Number of angles to use to test for preferred orientation\n",
    "vars = np.random.lognormal(2, 0.6, N)                               # Width of each neuron's tuning curve\n",
    "learning_rate = 0.01                                                # Learning rate\n",
    "\n",
    "n_days = 28                                                         # Number of days to run for\n",
    "n_norm_per_day = 1                                                  # How many times to normalise the weights per day  \n",
    "n_steps_per_norm = 30                                               # How many orientation stimuli per day\n",
    "n_steps = n_steps_per_norm * n_norm_per_day * n_days                # Number of steps to run for\n",
    "init_steps = 300                                                    # Number of trials to run to settle to a baseline\n",
    "\n",
    "hebb_scaling = 0.3                                                  # Scaling of Hebbian component  \n",
    "rand_scaling = 1                                                    # Scaling of random component \n",
    "\n",
    "W_init = initialise_W(N, vars)                                      # Initialise weights \n",
    "W_baseline = prerun(W_init, init_steps)                             # Settle to a baseline\n",
    "\n",
    "eo = 2                                                              # Plot every other \"x\" values (for visual clarity)\n",
    "\n",
    "\"\"\" Baseline \"\"\" \n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'baseline')\n",
    "drift_magnitude_baseline, drift_rate_baseline, convergence_baseline = get_metrics(N, n_days, theta_stim, POs)\n",
    "\n",
    "\n",
    "\"\"\" 28 day stripe-rearing \"\"\"\n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'stripe_rearing')\n",
    "drift_magnitude_28, drift_rate_28, convergence_28 = get_metrics(N, n_days, theta_stim, POs)\n",
    "\n",
    "\"\"\" 7 day stripe-rearing \"\"\" \n",
    "\n",
    "POs = get_POs_over_trials_7(W_baseline, n_steps)\n",
    "drift_magnitude_7, drift_rate_7, convergence_7 = get_metrics(N, n_days, theta_stim, POs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_3d(drift_magnitude_28, drift_magnitude_baseline, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_magnitude_28, axis=1)[:-1][::eo], c='green', ls='-', marker='o', ms=4, label='Deprivation 28 days', clip_on=False)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_magnitude_baseline, axis=1)[:-1][::eo], c='black', ls='-', marker='o', ms=4, label='Baseline', clip_on=False)\n",
    "    ax.set_ylim([0, 5]); ax.set_yticks([0, 5])\n",
    "    ax.set_xlabel('time since start [days]')\n",
    "    ax.set_ylabel(r'drift magnitude $ \\; [\\degree]$')\n",
    "    ax.set_xlim(0, 30)\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 3e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_3e(drift_rate_28, drift_rate_baseline, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_rate_28, axis=1)[:-1][::eo], c='green', ls='-', marker='o', ms=4, label='Deprivation 28 days', clip_on=False)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_rate_baseline, axis=1)[:-1][::eo], c='black', ls='-', marker='o', ms=4, label='Baseline', clip_on=False)\n",
    "    ax.set_ylim([0, 5]); ax.set_yticks([0, 5])\n",
    "    ax.set_xlabel('time since start [days]')\n",
    "    ax.set_ylabel(r'drift rate $ \\; [\\degree / $ day $]$')\n",
    "    ax.set_xlim(0, 30)\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp. Fig. 3j (left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supp_fig_3j_left(drift_magnitude_7, drift_magnitude_28, drift_magnitude_baseline, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2.5, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days+1)[::eo], np.median(drift_magnitude_7[:-1], axis=1)[::eo], c='orange', ls='-', marker='o', ms=4, label='Deprivation 7 days')\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_magnitude_28[:-1], axis=1)[::eo], c='green', ls='-', marker='o', ms=4, label='Deprivation 28 days')\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_magnitude_baseline[:-1], axis=1)[::eo], c='black', ls='-', marker='o', ms=4, label='Baseline')\n",
    "    ax.set_ylim([0, 5]); ax.set_yticks([0, 5])\n",
    "    ax.set_xlim([0, n_days+1])\n",
    "    for x in np.arange(7, n_days+1, 7): ax.axvline(x=x, c='k', ls='--', alpha=0.1, lw=1)\n",
    "    ax.set_xlabel('time since start [days]')\n",
    "    ax.set_ylabel(r'drift magnitude $ \\; [\\degree]$')\n",
    "    ax.set_xlim(0, 30)\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp. Fig. 3j (right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supp_fig_3j_right(convergence_7, convergence_28, convergence_baseline, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2.5, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_7, axis=1)[::eo], c='orange', ls='-', marker='o', ms=4)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_28, axis=1)[::eo], c='green', ls='-', marker='o', ms=4)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_baseline, axis=1)[::eo], c='black', ls='-', marker='o', ms=4)\n",
    "    ax.set_ylim([-2, 5]); ax.set_xlim(0, 30)\n",
    "    for x in np.arange(7, n_days+1, 7): ax.axvline(x=x, c='k', ls='--', alpha=0.1, lw=1)\n",
    "    ax.locator_params(axis='y', nbins=2)\n",
    "    ax.set_xlabel('time since start [days]')\n",
    "    ax.set_ylabel(r'convergence $ \\; [\\degree]$')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_3f(convergence_28, convergence_baseline, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_28, axis=1)[::eo], c='green', ls='-', marker='o', ms=4)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_baseline, axis=1)[::eo], c='black', ls='-', marker='o', ms=4)\n",
    "    ax.set_ylim([-2, 5]); ax.set_xticks([0, 7, 14, 21, 28])\n",
    "    ax.locator_params(axis='y', nbins=2)\n",
    "    ax.set_xlabel('Time since start [days]')\n",
    "    ax.set_ylabel(r'Convergence $ \\; [\\degree]$')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Knockouts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)                                                   # Set random seed\n",
    "N = int(500)                                                        # Number of neurons\n",
    "\n",
    "a=10                                                                # Parameters for propensity function\n",
    "theta_stim = 90                                                     # Angle to stimulate at \n",
    "n_test_angles = 100                                                 # Number of angles to use to test for preferred orientation\n",
    "vars = np.random.lognormal(2, 0.6, N)                               # Width of each neuron's tuning curve\n",
    "learning_rate = 0.01                                                # Learning rate\n",
    "\n",
    "n_days = 28                                                         # Number of days to run for\n",
    "n_norm_per_day = 2                                                  # How many times to normalise the weights per day     --> If too high, leads to greater drift rate?\n",
    "n_steps_per_norm = 15       # from 30                               # How often to normalise the weights  --> If too high (>20), leads to greater drift magnitude\n",
    "n_steps = n_steps_per_norm * n_norm_per_day * n_days                # Number of steps to run for\n",
    "init_steps = 300                                                    # Number of trials to run to settle to a baseline\n",
    "\n",
    "rand_scaling = 1\n",
    "hebb_scaling = 0.3      \n",
    "W_init = initialise_W(N, vars)                                      # Initialise weights \n",
    "W_baseline = prerun(W_init, init_steps)                             # Settle to a baseline\n",
    "\n",
    "hebb_color = 'deeppink'                                             # Colours for plotting\n",
    "rand_color = 'deepskyblue'\n",
    "opt_color = 'black'\n",
    "\n",
    "\n",
    "\"\"\" ----------  BASELINE ---------- \"\"\"\n",
    "\n",
    "# Hebbian only \n",
    "\n",
    "rand_scaling = 0\n",
    "hebb_scaling = 1.3\n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'baseline')\n",
    "drift_magnitude_baseline_hebb, drift_rate_baseline_hebb, convergence_baseline_hebb = get_metrics(N, n_days, theta_stim, POs)\n",
    "\n",
    "# Random only\n",
    "\n",
    "rand_scaling = 1.3\n",
    "hebb_scaling = 0\n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'baseline')\n",
    "drift_magnitude_baseline_rand, drift_rate_baseline_rand, convergence_baseline_rand = get_metrics(N, n_days, theta_stim, POs)\n",
    "\n",
    "# Optimal \n",
    "\n",
    "rand_scaling = 1\n",
    "hebb_scaling = 0.3\n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'baseline')\n",
    "drift_magnitude_baseline_opt, drift_rate_baseline_opt, convergence_baseline_opt = get_metrics(N, n_days, theta_stim, POs)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" ----------  STRIPE-REARING ---------- \"\"\"\n",
    "\n",
    "\"\"\" Hebbian only \"\"\" \n",
    "\n",
    "rand_scaling = 0\n",
    "hebb_scaling = 1.3\n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'stripe_rearing')\n",
    "drift_magnitude_sr_hebb, drift_rate_sr_hebb, convergence_sr_hebb = get_metrics(N, n_days, theta_stim, POs)\n",
    "\n",
    "\"\"\" Random only \"\"\"\n",
    "\n",
    "rand_scaling = 1.3\n",
    "hebb_scaling = 0\n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'stripe_rearing')\n",
    "drift_magnitude_sr_rand, drift_rate_sr_rand, convergence_sr_rand = get_metrics(N, n_days, theta_stim, POs)\n",
    "\n",
    "\"\"\" Optimal \"\"\"\n",
    "\n",
    "rand_scaling = 1\n",
    "hebb_scaling = 0.3\n",
    "\n",
    "POs = get_POs_over_trials(W_baseline, n_steps, 'stripe_rearing')\n",
    "drift_magnitude_sr_opt, drift_rate_sr_opt, convergence_sr_opt = get_metrics(N, n_days, theta_stim, POs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp. Fig. 3h (left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supp_fig_3h_left(drift_magnitude_baseline_hebb, drift_magnitude_baseline_rand, drift_magnitude_baseline_opt, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2.5, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_magnitude_baseline_hebb[:-1], axis=1)[::eo], c=hebb_color, ls='-', marker='o', ms=4, label='Hebbian only')\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_magnitude_baseline_rand[:-1], axis=1)[::eo], c=rand_color, ls='-', marker='o', ms=4, label='Random only')\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(drift_magnitude_baseline_opt[:-1], axis=1)[::eo], c=opt_color, ls='-', marker='o', ms=4, label='Optimal')\n",
    "    ax.locator_params(axis='y', nbins=2)\n",
    "    ax.set_ylim([0, 5]); ax.set_yticks([0, 5]); ax.set_xticks([0, 7, 14, 21, 28])\n",
    "    ax.set_xlabel('time since start [days]')\n",
    "    ax.set_ylabel(r'drift magnitude $ \\; [\\degree]$')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp. Fig. 3h (right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supp_fig_3h_right(drift_rate_baseline_hebb, drift_rate_baseline_rand, drift_rate_baseline_opt, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2.5, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.mean(drift_rate_baseline_hebb, axis=1)[::eo], c=hebb_color, ls='-', marker='o', ms=4)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.mean(drift_rate_baseline_rand, axis=1)[::eo], c=rand_color, ls='-', marker='o', ms=4)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.mean(drift_rate_baseline_opt, axis=1)[::eo], c=opt_color, ls='-', marker='o', ms=4)\n",
    "    ax.set_ylim([0, 5]); ax.set_yticks([0, 5]); ax.set_xticks([0, 7, 14, 21, 28])\n",
    "    ax.set_xlabel('time since start [days]')\n",
    "    ax.set_ylabel(r'drift rate $ \\; [\\degree / $ day $]$')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp. Fig. 3i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supp_fig_3i(convergence_sr_hebb, convergence_sr_rand, convergence_sr_opt, n_days):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2.5, 2), dpi=180)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_sr_hebb, axis=1)[::eo], c=hebb_color, ls='-', marker='o', ms=4)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_sr_rand, axis=1)[::eo], c=rand_color, ls='-', marker='o', ms=4)\n",
    "    ax.plot(np.arange(1, n_days)[::eo], np.median(convergence_sr_opt, axis=1)[::eo], c='green', ls='-', marker='o', ms=4)\n",
    "    ax.set_ylim([-2, 8]); ax.set_yticks([0, 5]); ax.set_xticks([0, 7, 14, 21, 28])\n",
    "    ax.locator_params(axis='y', nbins=2)\n",
    "    ax.set_xlabel('time since start [days]')\n",
    "    ax.set_ylabel(r'convergence $ \\; [\\degree]$')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_3k(drift_magnitude_baseline_opt, drift_magnitude_baseline_rand, drift_magnitude_baseline_hebb):\n",
    "    colors = [opt_color, rand_color, hebb_color]\n",
    "    magnitude_values = [np.median(drift_magnitude_baseline_opt[-1]), np.median(drift_magnitude_baseline_rand[-1]), np.median(drift_magnitude_baseline_hebb[-1])] \n",
    "    fig, ax = plt.subplots(figsize=(2, 3), dpi=180)\n",
    "    ax.bar([0, 3, 6], magnitude_values, color=colors, width=1, label='magnitude')\n",
    "    ax.set_ylabel(r'baseline drift magnitude $ \\; [\\degree]$')\n",
    "    ax.set_xticks([0, 3, 6]); ax.set_xlim([-1, 7]); ax.set_ylim([0, 9]); ax.set_yticks([0, 5])\n",
    "    ax.set_xticklabels(['model', 'random only', 'hebbian only'], rotation=50, ha='right')\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 3j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_3j(convergence_sr_opt, convergence_sr_rand, convergence_sr_hebb):\n",
    "    colors = ['green', rand_color, hebb_color]\n",
    "    convergence_values = [np.median(convergence_sr_opt[-1]), np.median(convergence_sr_rand[-1]), np.median(convergence_sr_hebb[-1])]\n",
    "    fig, ax = plt.subplots(figsize=(2, 3), dpi=180)\n",
    "    ax.bar([0, 3, 6], convergence_values, color=colors, width=1, label='convergence')\n",
    "    ax.set_ylabel(r'convergence $ \\; [\\degree]$')\n",
    "    ax.set_xticks([0, 3, 6]); ax.set_xlim([-1, 7]); ax.set_ylim([0, 9]); ax.set_yticks([0, 5])\n",
    "    ax.set_xticklabels(['model', 'random only', 'hebbian only'], rotation=50, ha='right')\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f2c2030d2c2d87f3843e39674442619aef6da99be1b246f3be91ffea5723ba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
